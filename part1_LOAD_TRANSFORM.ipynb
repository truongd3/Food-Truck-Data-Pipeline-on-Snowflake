{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "tn3vrebwmu2awpq5iqoy",
   "authorId": "1350651777198",
   "authorName": "USER",
   "authorEmail": "",
   "sessionId": "3a46f1c0-0b6a-4c22-ada6-184fb3a9cd1a",
   "lastEditTime": 1759509125850
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087ecc02-bbc7-488d-beae-796574cfed71",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Part 1: Performing Interactive Data Analytics\n\nIn this part, we load our data into Snowflake and work with it using [pandas on Snowflake](https://docs.snowflake.com/developer-guide/snowpark/python/pandas-on-snowflake)."
  },
  {
   "cell_type": "markdown",
   "id": "e0a89459-6d2e-4a33-8f7f-0ba3127468a2",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "## Adding Python Packages ðŸŽ’\n\nSnowflake Notebooks comes pre-installed with common Python libraries for data science ðŸ§ª and machine learning ðŸ§ ! If we are looking to use other packages, click on the `Packages` dropdown on the top right to add additional packages to your notebook.\n\nFor the purpose of this demo, let's add the `modin` package to use [pandas on Snowflake](https://docs.snowflake.com/developer-guide/snowpark/python/pandas-on-snowflake) to work with our data."
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "import streamlit as st\nimport modin.pandas as pd\nimport snowflake.snowpark.modin.plugin",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f0374405-b02f-4ddf-95e3-2b281c54480e",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "## Connecting to Snowflake \n\nTo work with data in Snowflake, we need to first get a session variable to connect to Snowflake. Since we're already logged in to Snowflake Notebook, we can get the session variable directly through the active notebook session. The session variable is the entrypoint that gives us access to using Snowflake's Python API, including Snowpark."
  },
  {
   "cell_type": "code",
   "id": "3e55fa97-d8ac-49a2-8e0b-4c4e40a635b0",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd6e3bba-c22d-4fd4-81a0-a75fc60e98e3",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "## Bringing data into Snowflake\n\nFirst, let's create an external state and upload the CSV file.\n"
  },
  {
   "cell_type": "code",
   "id": "1973fc8a-c443-4b0f-a5fe-6aa3933511d9",
   "metadata": {
    "language": "sql",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Create a external stage \nCREATE OR REPLACE STAGE FROSTBYTES\n    URL = 's3://sfquickstarts/frostbyte_tastybytes/';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bab997af-990b-4747-af20-a5477e79597a",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item = pd.read_csv(\"@frostbytes/analytics/menu_item_aggregate_v.csv\")\nmenu_item.head()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb6d40c5-2a63-4465-a337-680258ca9819",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "## Profiling and summary statistics\nWe can look at the size and overall descriptive statistics of our dataframe `menu_item`.  "
  },
  {
   "cell_type": "code",
   "id": "b7aa66fa-54e6-4df6-8dd4-86a72e54c0a5",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7c75ba0-12b7-4512-a5ca-18cf4b66293e",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item.describe()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7162683-eecf-46c6-ade2-a7dc1db2172a",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import altair as alt\nnumeric_cols = ['PRICE', 'BASE_PRICE', 'COST_OF_GOODS_USD', 'COUNT_ORDERS', 'TOTAL_QUANTITY_SOLD']\ncols = st.columns(len(numeric_cols))\nfor idx, col in enumerate(numeric_cols):\n    with cols[idx]:\n        chart = alt.Chart(menu_item).mark_bar().encode(\n            alt.X(f'{col}:Q', bin=True, title=col),\n            alt.Y('count():Q', title='Count'),\n            tooltip=['count()']\n        ).properties(\n            width=200,  \n            height=300,\n            title=f'Distribution of {col}'\n        ).configure_title(\n            fontSize=14 \n        )\n        st.altair_chart(chart, use_container_width=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f33c330-431b-40d1-978b-d93d00670653",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": "## Data Cleaning and Transformation\n\nNow let's clean up the data by performing some data transformation.\n"
  },
  {
   "cell_type": "code",
   "id": "9c946c47-1bc0-4103-9f9a-7dd23e21a2b9",
   "metadata": {
    "language": "python",
    "name": "cell16",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item[\"DATE\"] = pd.to_datetime(menu_item[\"DATE\"])\nmenu_item.head(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01437560-ec79-41cd-8467-62203a4c0c28",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "Let's compute the total revenue by multiplying the two columns together. "
  },
  {
   "cell_type": "code",
   "id": "91834d45-dfc9-4d7b-844f-a37deb58235a",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item[\"TOTAL_REVENUE\"] = menu_item[\"TOTAL_QUANTITY_SOLD\"]*menu_item[\"PRICE\"]\nmenu_item.head(10)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e173b7ee-8c37-48fa-9817-9829ec85cb9c",
   "metadata": {
    "language": "python",
    "name": "cell19",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "weekly_total = menu_item.groupby(\"DAY_OF_WEEK\")[\"TOTAL_REVENUE\"].sum()\nweekly_total",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72810937-01d0-4a54-8a5b-3d1340ee43ca",
   "metadata": {
    "name": "cell20"
   },
   "source": "Next, we want to classify `DAY_TYPE` weekday/weekend using a mapping dictionary.\n"
  },
  {
   "cell_type": "code",
   "id": "c90a3dff-9dca-4cb5-a69d-3cd1651fbc09",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Convert the series to a dataframe and reset index for Altair\nweekly_total_df = weekly_total.reset_index()\nday_type = {0: 'Weekend',  1: 'Weekday',  2: 'Weekday',  3: 'Weekday',  4: 'Weekday',  5: 'Weekday',  6: 'Weekend'}\n# Add day type classification\nweekly_total_df['DAY_TYPE'] = weekly_total_df['DAY_OF_WEEK'].map(day_type)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb610b57-65b3-44b3-a0cc-acb76b791fb5",
   "metadata": {
    "language": "python",
    "name": "cell22",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "chart = alt.Chart(weekly_total_df).mark_bar().encode(\n    x=alt.X('DAY_OF_WEEK:O', title='Day of Week'),\n    y=alt.Y('TOTAL_REVENUE:Q', title='Total Revenue'),\n    color=alt.Color('DAY_TYPE:N', \n                    scale=alt.Scale(domain=['Weekday', 'Weekend'],\n                                  range=['#1f77b4', '#ff7f0e'])),\n).properties(\n    width=600,\n    height=400,\n    title='Total Revenue by Day of Week (Weekday vs Weekend)'\n)\n\n# Display the chart\nst.altair_chart(chart, use_container_width=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a816c3bb-7d32-4837-8747-f88c9079b018",
   "metadata": {
    "name": "cell23",
    "collapsed": false
   },
   "source": "We are interested in looking specifically at the sales of Buffalo Mac & Cheese across different food trucks. "
  },
  {
   "cell_type": "code",
   "id": "da82a32c-cc56-4473-a01e-be9108c6b01e",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "buffalo_mac_cheese = menu_item[menu_item[\"MENU_ITEM_NAME\"]==\"Buffalo Mac & Cheese\"]\nbuffalo_mac_cheese",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb46639d-66d1-4956-a91c-60c4749a9858",
   "metadata": {
    "name": "cell25",
    "collapsed": false
   },
   "source": "Next, we perform a join to combine our `buffalo_mac_cheese` dataframe with another dataframe `order_item`."
  },
  {
   "cell_type": "code",
   "id": "86a9aff5-f9d2-4db1-8b22-68e7d3caa0d9",
   "metadata": {
    "language": "python",
    "name": "cell26",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "order_item = pd.read_csv(\"@frostbytes/analytics/order_item_cost_agg_v.csv\")\norder_item",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eeff2987-d49a-44bc-bc7f-d17578fea1ef",
   "metadata": {
    "name": "cell28"
   },
   "source": "By looking at `order_item`, we see that it has separate month year columns, but `buffalo_mac_cheese` (from the original `menu_item`) has one combined `DATE`, so let's extract the year and month column."
  },
  {
   "cell_type": "code",
   "id": "ce63e2ad-3cb0-4c1a-b565-c6a98996ec08",
   "metadata": {
    "language": "python",
    "name": "cell29",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Extract year and month to conform with data in `order_item`\nbuffalo_mac_cheese['YEAR'] = buffalo_mac_cheese['DATE'].dt.year\nbuffalo_mac_cheese['MONTH'] = buffalo_mac_cheese['DATE'].dt.month",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a5224e9-a3ec-40e1-bdd8-13db45bcd52b",
   "metadata": {
    "name": "cell30",
    "collapsed": false
   },
   "source": "Now let's `groupby` the year month and menu type."
  },
  {
   "cell_type": "code",
   "id": "f38268f7-a838-4a00-b569-eff45ad6261a",
   "metadata": {
    "language": "python",
    "name": "cell31",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Group by YEAR and MONTH\ngrouped_bmc = buffalo_mac_cheese.groupby(['YEAR', 'MONTH','MENU_TYPE_ID'])[\"COUNT_ORDERS\",\"TOTAL_QUANTITY_SOLD\"].sum().reset_index()\ngrouped_bmc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b173a162-7f17-4783-8e87-fcf945425e1f",
   "metadata": {
    "name": "cell32",
    "collapsed": false
   },
   "source": "Now that we have the same join key on the two tables, we can merge the columns together."
  },
  {
   "cell_type": "code",
   "id": "7c02d63a-e95f-4675-83ec-1a7946045731",
   "metadata": {
    "language": "python",
    "name": "cell33",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Now merge with order_item on YEAR and MONTH\nmerged_df = grouped_bmc.merge(order_item, on=['YEAR', 'MONTH'])\nmerged_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69999655-e385-4e59-9939-b97b7709e49d",
   "metadata": {
    "language": "python",
    "name": "cell34",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "st.markdown(\"This is how the dataframe size changed from performing the merge operation:\")\nst.markdown(f\"order_item size: {order_item.shape} + grouped_bmc size: {grouped_bmc.shape} -> merged_df size: {merged_df.shape}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "05333cd5-3264-483c-b601-889dd19a76af",
   "metadata": {
    "name": "cell35",
    "collapsed": false
   },
   "source": "Now, save the output dataframe as a **Snowflake** table. "
  },
  {
   "cell_type": "code",
   "id": "5a383615-70c7-48a6-8e80-f9305e25d16a",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": "merged_df.to_snowflake(\"cleaned_table\", index= None, if_exists=\"replace\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8bf0a1f6-0319-4c67-8ab7-b2c0feb34301",
   "metadata": {
    "name": "cell37"
   },
   "source": "Now we can query this table directly using SQL to verify that the table has been created."
  },
  {
   "cell_type": "code",
   "id": "5e6bd648-1bd4-4456-808d-7c601c2479af",
   "metadata": {
    "language": "sql",
    "name": "cell38",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM cleaned_table LIMIT 5; ",
   "execution_count": null
  }
 ]
}