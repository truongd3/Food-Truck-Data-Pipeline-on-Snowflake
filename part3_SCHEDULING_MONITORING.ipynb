{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "fckq5yiihim4mj4c6ium",
   "authorId": "1350651777198",
   "authorName": "USER",
   "authorEmail": "tdd4@njit.edu",
   "sessionId": "4716a68f-4368-47b0-ab34-97290bdb0e14",
   "lastEditTime": 1759615540618
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32acc9a-10cd-4ab6-874c-4ababd3c91c3",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Part 3: Bringing Workflows to Production\n\n## Scheduling Python Jobs\n\nIn Snowflake, [Tasks](https://docs.snowflake.com/en/user-guide/tasks-intro) are used to automate and schedule jobs. Tasks can schedule the execution of a Notebook, a stored procedure, or arbitrary SQL statements. Let's use a Task to schedule a Python Stored Procedure to apply the Customer Loyalty Score UDAF on a schedule. Next, we will set up telemetry collection for the job and set up alerts.\n\n## Creating a Python Stored Procedure\n\n[Stored Procedures](https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-overview) allow us to run *procedural* code, like loops, if/else blocks, and other patterns which are hard to do in SQL alone. \n\nTo create a Python Stored Procedure, all we need is a Python function that accepts a Snowpark Session object as its first argument. In Snowflake we call this the \"handler\" for the procedure. For example, the Python function below is a bare-bones procedure handler that uses the Session object which returns an integer:\n\n```python\nfrom snowflake.snowpark import Session\n\ndef my_handler(sess: Session) -> int:\n    n_rows = sess.table('my_table').count()\n    return n_rows\n```\n\nLet's create a procedure to calculate the Customer Loyalty scores and write them to an output table. Then, we will schedule it with a Task so we can have up-to-date loyalty scores. "
  },
  {
   "cell_type": "markdown",
   "id": "1a2601b6-8e5f-495a-88be-7a09d0858883",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "In the package picker, add the package `snowflake.core`. This package is the [Python API for Snowflake](https://docs.snowflake.com/en/developer-guide/snowflake-python-api/reference/latest/index)."
  },
  {
   "cell_type": "code",
   "id": "85c1943f-1386-4094-a3b8-81b5431cc746",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom datetime import datetime\nfrom snowflake.snowpark.functions import lit\nimport logging\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2cf1c890-23b0-422d-9f46-ed6d4de0ee0b",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.types import IntegerType\n\n# Handler for the procedure\ndef calc_loyalty_scores(sess: Session) -> int:\n    logging.info('Starting loyalty score procedure')\n    calculated_at = datetime.now()\n    \n    sess.sql(\"\"\"\n        SELECT\n          CUSTOMER_ID,\n          LoyaltyScoreUDAF(ORDER_TOTAL, ORDER_TS) AS loyalty_score\n        FROM tasty_bytes_orders\n        WHERE \n            ORDER_TOTAL IS NOT NULL \n            AND ORDER_TS IS NOT NULL\n            AND CUSTOMER_ID IS NOT NULL\n        GROUP BY CUSTOMER_ID\n        ORDER BY loyalty_score DESC\n    \"\"\").with_column(\"calculated_at\", lit(calculated_at))\\\n    .write\\\n    .save_as_table('loyalty_scores', mode='append')\n\n    # Returns the number of rows in the output table\n    return sess.table('tasty_bytes_orders').count()\n\n\n# Register the handler as a Stored Procedure\nloyalty_sproc = session.sproc.register(\n    calc_loyalty_scores,\n    return_type=IntegerType(),\n    name='calculate_loyalty_scores',\n    is_permanent=True,\n    packages=['snowflake-telemetry-python'],\n    stage_location='@my_stage/',\n    replace=True\n)\n\nprint(f'Created procedure \"{loyalty_sproc.name}\"')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00b0acbd-7065-4754-93e7-d669818fc079",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Call the stored proc for a test run\nCALL CALCULATE_LOYALTY_SCORES();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24b8201c-f131-4fe6-9954-43382fb9a5ee",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "If we click **Monitoring** > **Query History** from the table of contents on the left, we should be able to see the `CALL CALCULATE_LOYALTY_SCORES();` query in the list. (Tip: hold Ctrl as we click **Query History** to open it in a new tab.)"
  },
  {
   "cell_type": "markdown",
   "id": "90f938b9-3d17-47fe-b846-a364815fb12a",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "Now let's create a Task to run this stored procedure on a schedule. Check out the docs on [`CREATE TASK`](https://docs.snowflake.com/en/sql-reference/sql/create-task) for more information, but at its core a Task needs a **schedule** and a **warehouse**. For example, the SQL below defines a Task that runs every hour with the Warehouse, `my_wh`, and calls a stored procedure named `my_stored_procedure`.\n\n```sql\nUSE DATABASE TEST_DB;\nUSE SCHEMA TEST_SCHEMA;\n\nCREATE TASK my_task\n  WAREHOUSE = my_wh\n  SCHEDULE = '60 MINUTES'\n  AS\n    CALL my_stored_procedure\n```\n\nAnd of course, you can define the same Task using Python!\n\n```python\nfrom datetime import timedelta\nfrom snowflake.core.task import Cron, Task\n\ntasks = root.databases[\"TEST_DB\"].schemas[\"TEST_SCHEMA\"].tasks\n\ntask = tasks.create(\n    Task(\n        name=\"my_task\",\n        definition=\"CALL my_stored_procedure\",\n        schedule=Cron(\"0 * * * *\", \"America/Los_Angeles\"),\n        warehouse=\"my_wh\"\n    ),\n)\n```"
  },
  {
   "cell_type": "code",
   "id": "1c93436e-79a0-4f0f-88c4-13e1cb09ceaf",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "# Let's create a Task in Python\nfrom snowflake.core import Root\nfrom snowflake.core.task import Cron, Task\n\nroot = Root(session)\ntasks = root.databases[\"HOL_DB\"].schemas[\"PUBLIC\"].tasks\nschedule = Cron(\"*/5 * * * *\", \"America/Los_Angeles\")  # every 5 minutes\n\ntask = tasks.create(\n    Task(\n        name=\"loyalty_score\",\n        definition=\"CALL HOL_DB.PUBLIC.CALCULATE_LOYALTY_SCORES();\",\n        schedule=schedule,\n        warehouse=\"my_wh\"\n    ),\n    mode=\"orreplace\"\n)\n\n# Start the task, will run every 5 minutes now\ntask.resume()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ac7e2fd-0a09-46f7-8b18-2554fae3fad5",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "Now the Task, `loyalty_score`, should be running _every 5 minutes_. In the Database browser on the left, find your database and under the PUBLIC schema you should see the `loyalty_score` Task listed under the *Tasks* tab.\n\n![Task Location](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/navigate_to_task.png) \n\nClick the task and it will bring you to the page for the Task. Click the **Run History** page to see the executions of the Task.\n\nRemember, the task is running every 5th minute, so you may not see an execution in the history tab right away. You can call [`task.execute()`](https://docs.snowflake.com/en/developer-guide/snowflake-python-api/reference/latest/_autosummary/snowflake.core.task.TaskResource#snowflake.core.task.TaskResource) to force an execution of the task independent of its schedule."
  },
  {
   "cell_type": "code",
   "id": "5e5ac7a1-84b3-4086-9fb6-84cffdf7576a",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Now let's stop the Task's execution\ntask.suspend()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "da1ad170-89b1-44e7-8a39-c6473725960a",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "## Monitoring Python Workloads\n\nNow we have a simple Python job scheduled to execute every 5 minutes. This raises the question: how do we monitor this job as it's running? How can we be notified if it fails overnight? How can we track performance over time? Snowflake provides a [suite of observability capabilities](https://www.snowflake.com/en/product/features/snowflake-trail/) to help you address those questions. Let's go over a few of Snowflake's observability capabilities:\n\n1. Telemetry Collection: You can route any [logs](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging), [metrics](https://docs.snowflake.com/en/developer-guide/logging-tracing/metrics), or [traces](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing) from your jobs to Snowflake's Event Tables for storage and alerting.\n1. History tables: Use the [Query History](https://docs.snowflake.com/en/user-guide/ui-snowsight-activity), [Copy History](https://docs.snowflake.com/en/user-guide/data-load-monitor), and [Task History](https://docs.snowflake.com/en/user-guide/ui-snowsight-tasks) to monitor all usage in your account.\n1. [Alerts and Notifications](https://docs.snowflake.com/en/developer-guide/builders/observability#label-observability-alerts-notifications): Alerts allow for customizable triggering conditions, actions, and a schedule, in combination with notification integrations for proactive monitoring.\n1. [Extensibility with third-party tools](https://docs.snowflake.com/en/developer-guide/builders/observability#label-observability-tools-analysis-visualization): The Snowflake [event table](https://docs.snowflake.com/en/developer-guide/logging-tracing/event-table-setting-up) adopts [OpenTelemetry](https://opentelemetry.io/docs/) standards, so your Snowflake telemetry can easily be consumed by other ecosystem tools."
  },
  {
   "cell_type": "markdown",
   "id": "1c0d995d-a2ce-41cd-a6fa-5de1c33126d5",
   "metadata": {
    "name": "cell12",
    "collapsed": false
   },
   "source": "## Event Table Setup\n\nThe Event Table is the central storage system for logs, metrics, and traces in your account. A [default Event Table](https://docs.snowflake.com/developer-guide/logging-tracing/event-table-setting-up#use-the-default-event-table) is already created at `snowflake.telemetry.events`. Let's enable it:"
  },
  {
   "cell_type": "code",
   "id": "20d9b603-5d00-4e5c-bce6-0e654b3686c2",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "ALTER ACCOUNT SET EVENT_TABLE = snowflake.telemetry.events;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "119bb4e8-ac78-4ac7-9fff-d79905b97891",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "Next, we'll enable the collection of logs, metrics, and traces in our account."
  },
  {
   "cell_type": "code",
   "id": "32bff270-e3e6-494e-a695-bd0a33068035",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": "ALTER ACCOUNT SET LOG_LEVEL = 'INFO';\nALTER ACCOUNT SET METRIC_LEVEL = 'ALL';\nALTER ACCOUNT SET TRACE_LEVEL = 'ALWAYS';",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7af20828-fe80-48cd-90fc-a79f433d72b7",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "We're now collecting logs, metrics, and traces for all jobs in our account. To test this, let's run our Task again. "
  },
  {
   "cell_type": "code",
   "id": "dba2072d-0f25-48f7-8dcd-d6d48cbf9df0",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": "task.execute()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "17d5a7af-ab08-491d-8732-9bcf1ef6023f",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "After running this procedure, go to **Monitoring** > **Traces and Logs** > **Log Explorer**. You should see the log message \"`Starting loyalty score procedure`\" from the procedure in the **Log Explorer**. You can use the filters at the top to find the log message. Look under the Object column for the name of the procedure, \"`CALCULATE_LOYALTY_SCORES()`\". (Tip: you can open the **Monitoring** page in a new browser tab by holding Ctrl as you click the tab.)\n\n![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/log_explorer.png)\n\nClick that log line and a pane will open on the right with more information about the log entry, like the object which emitted it, the warehouse used, and the file and line where the log line was emitted from. \n\nClick the button to go the Query associated with the log.\n\n![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/link_to_query_page.png)\n"
  },
  {
   "cell_type": "markdown",
   "id": "f91b0409-9b94-4bb2-b33d-fe342a57cc95",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "In the page for the Query, the \"Query Telemetry\" tab will show the trace diagram for the job. In this page, each row is a **span** representing a unit of work. In this case, there are spans for the Stored Procedure execution, the DataFrame queries, and the UDAF. \n\n![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/trace_diagram.png)\n\nThe concept of [spans and traces](https://opentelemetry.io/docs/concepts/observability-primer/#distributed-traces) come from [OpenTelemetry](https://opentelemetry.io/), a project in the Cloud Native Compute Foundation. OpenTelemetry is often used in observability for application infrastructure, and Snowflake has applied it to native primitives such as Stored Procedures, UDFs, DataFrames, and soon to Queries, Tasks, Notebooks, Snowpark Container Services, and more!"
  },
  {
   "cell_type": "markdown",
   "id": "e5eca549-d161-4984-b4ec-68b33fd63907",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "## Custom Telemetry\n\n### Logs\n\nSnowflake will collect any logs emitted by our Python code, even logs from packages we're calling. If we want to add more logs to our jobs so we can monitor and debug better in the future, we can just run `import logging` and add logging statements like `logging.warn(\"This is a warning message\")`. [More information](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-python#stored-procedure-example).\n\n### Span Events\n\nWe can also add custom spans using [`telemetry.set_span_attribute()`](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing-python#adding-span-attributes), these are similar to logs but we can be more useful for attaching structured data like lists and dictionaries. This data will show in the \"Span Events\" tab of the Trace Diagram."
  },
  {
   "cell_type": "markdown",
   "id": "689e57c5-56d8-4817-9b51-63a65becdf4c",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "## Next Steps\n\n### Create email notifications \n\nUse logs, metrics, and traces to create an alert if a job throws an error log or if a Task fails. This is a great way to stay on top of scheduled data pipelines. To do so, use Snowflake's [alerts](http://docs.snowflake.com/en/user-guide/alerts) feature.\n\n- [`SYSTEM$SEND_EMAIL()`](https://docs.snowflake.com/en/sql-reference/stored-procedures/system_send_email)\n- [Send email notifications](https://docs.snowflake.com/en/user-guide/notifications/email-notifications)\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "90ce1740-5f21-4753-99ac-5db81d5b86ca",
   "metadata": {
    "name": "cell24",
    "collapsed": false
   },
   "source": "#### Step 1: Create a Notification Integration\n\nThis is a Snowflake object that establishes a connection between Snowflake and an email server, allowing Snowflake to send emails."
  },
  {
   "cell_type": "code",
   "id": "2c824a65-d671-494d-b5c7-fda72c49647a",
   "metadata": {
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE NOTIFICATION INTEGRATION send_email_notification\n    TYPE=EMAIL\n    ENABLED=TRUE\n    ALLOWED_RECIPIENTS=('bryan.blancomorales@snowflake.com','tdd4@njit.edu');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d32fe246-2de4-4af1-91d7-eb43a31f8b66",
   "metadata": {
    "name": "cell25",
    "collapsed": false
   },
   "source": "#### Step 2: Create an Alert to Monitor for Failures\n\nCreate an `ALERT`. This object will run on a schedule, check for a failed task, and send an email if the condition is met. This alert will query the `TASK_HISTORY` to see if the `loyalty_score` task has failed recently."
  },
  {
   "cell_type": "code",
   "id": "aa96df64-5783-4b07-86d5-dbd33d8ee140",
   "metadata": {
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE ALERT loyalty_score_failure_alert\n    WAREHOUSE = my_wh\n    SCHEDULE = '10 MINUTE'\n    IF (EXISTS (\n        SELECT 1\n        FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n            SCHEDULED_TIME_RANGE_START => DATEADD('minute', -11, CURRENT_TIMESTAMP()),\n            TASK_NAME => 'LOYALTY_SCORE'\n        ))\n        WHERE STATE = 'FAILED'\n    ))\n    THEN\n        CALL SYSTEM$SEND_EMAIL(\n            'send_email_notification',\n            'tdd4@njit.edu',\n            'Snowflake Task Failure: LOYALTY_SCORE',\n            'The task named \"LOYALTY_SCORE\" in HOL_DB.PUBLIC has failed. Check the run history for details.'\n        );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "70812bce-228d-45ff-a2f9-862e9c6ee860",
   "metadata": {
    "name": "cell27",
    "collapsed": false
   },
   "source": "#### Step 3: Activate the Alert\n\nAlerts are created in a suspended state by default. We must resume the alert to activate it."
  },
  {
   "cell_type": "code",
   "id": "49d43d48-d160-4616-95a7-c6cbe3f33f21",
   "metadata": {
    "language": "sql",
    "name": "cell28"
   },
   "outputs": [],
   "source": "ALTER ALERT loyalty_score_failure_alert RESUME;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a4db874-c847-4bbb-8be1-7cc3213d2db4",
   "metadata": {
    "language": "sql",
    "name": "cell29"
   },
   "outputs": [],
   "source": "DESCRIBE ALERT loyalty_score_failure_alert;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c4371b8e-c724-46a9-85db-aeaac3d555a3",
   "metadata": {
    "name": "cell31",
    "collapsed": false
   },
   "source": "#### Step 4: Create a Failed Condition\n\nManually modify the Python function `calc_loyalty_scores` to query a table that does not exist, which will guarantee a SQL error. The code below changes `tasty_bytes_orders` to `tasty_bytes_orders_FAKE_TABLE`."
  },
  {
   "cell_type": "code",
   "id": "980eefc3-9a83-43a7-8633-f78e568004ac",
   "metadata": {
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom datetime import datetime\nfrom snowflake.snowpark.functions import lit\nimport logging\n\nfrom snowflake.snowpark.types import IntegerType\n\n# Handler for the procedure with an intentional error\ndef calc_loyalty_scores_fail(sess: Session) -> int:\n    logging.info('Starting loyalty score procedure (INTENTIONAL FAIL)')\n    calculated_at = datetime.now()\n\n    # This will fail because the table does not exist\n    sess.sql(\"\"\"\n        SELECT\n          CUSTOMER_ID,\n          LoyaltyScoreUDAF(ORDER_TOTAL, ORDER_TS) AS loyalty_score\n        FROM tasty_bytes_orders_FAKE_TABLE\n        WHERE\n            ORDER_TOTAL IS NOT NULL\n            AND ORDER_TS IS NOT NULL\n            AND CUSTOMER_ID IS NOT NULL\n        GROUP BY CUSTOMER_ID\n        ORDER BY loyalty_score DESC\n    \"\"\").with_column(\"calculated_at\", lit(calculated_at)).write.save_as_table('loyalty_scores', mode='append')\n\n    return sess.table('tasty_bytes_orders').count()\n\n# Register the faulty handler, replacing the original Stored Procedure\nsession.sproc.register(\n    calc_loyalty_scores_fail,\n    return_type=IntegerType(),\n    name='calculate_loyalty_scores', # Note: We use the original name to overwrite it\n    is_permanent=True,\n    packages=['snowflake-telemetry-python'],\n    stage_location='@my_stage/',\n    replace=True\n)\n\nprint('Faulty procedure \"calculate_loyalty_scores\" has been deployed.')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f1e4e3f0-87ee-4417-93ed-ff2bb585e123",
   "metadata": {
    "name": "cell33",
    "collapsed": false
   },
   "source": "Now, trigger the task manually to run the faulty stored procedure."
  },
  {
   "cell_type": "code",
   "id": "db42a9dc-df6b-4829-9c1a-d2f8d1e6d3ab",
   "metadata": {
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": "# Re-fetch the task object if needed\nfrom snowflake.core import Root\nroot = Root(session)\ntask = root.databases[\"HOL_DB\"].schemas[\"PUBLIC\"].tasks[\"loyalty_score\"]\n\ntask.execute()\nprint(\"Task execution triggered. It should now fail.\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7eb1da0-8bd3-4b48-815c-1a56d98e6c8e",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "#### RESULT\n\n_**Run History tab**_\n\n![task_run_history](https://i.imgur.com/tQMfVTE.png)\n\n_**Email Notification**_\n\n![email](https://i.imgur.com/Dno6QMU.png)\n"
  }
 ]
}