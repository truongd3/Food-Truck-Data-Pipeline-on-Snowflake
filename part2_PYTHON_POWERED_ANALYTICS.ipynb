{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "6rabni6qnvquti4kt4vq",
   "authorId": "1350651777198",
   "authorName": "USER",
   "authorEmail": "",
   "sessionId": "7dc08f34-61fe-4a06-ae37-0020e69ff5eb",
   "lastEditTime": 1759512924287
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89b55b2-41de-49ad-9655-b3a3fbc2fdcc",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": "# Part 2: Python Powered Analytics\n\nIn this section, we write User Defined Functions in Python and read from an external API. First, let's set up our Session and create an example table."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc224b2-e95c-48cf-b3b3-3451d3dbf883",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbeb563-983b-479e-87a6-76ec2be4222e",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": "-- Use the Orders dataset. Let's create a new table and import the data from S3\n\nCREATE OR REPLACE TABLE HOL_DB.PUBLIC.TASTY_BYTES_ORDERS (\n  ORDER_ID BIGINT,\n  TRUCK_ID INT,\n  ORDER_TS TIMESTAMP_TZ,\n  ORDER_DETAIL_ID BIGINT,\n  LINE_NUMBER INT,\n  TRUCK_BRAND_NAME STRING,\n  MENU_TYPE STRING,\n  PRIMARY_CITY STRING,\n  REGION STRING,\n  COUNTRY STRING,\n  FRANCHISE_FLAG BOOLEAN,\n  FRANCHISE_ID INT,\n  FRANCHISEE_FIRST_NAME STRING,\n  FRANCHISEE_LAST_NAME STRING,\n  LOCATION_ID INT,\n  PLACEKEY STRING,\n  LOCATION_NAME STRING,\n  TOP_CATEGORY STRING,\n  SUB_CATEGORY STRING,\n  LATITUDE FLOAT,\n  LONGITUDE FLOAT,\n  CUSTOMER_ID INT,\n  FIRST_NAME STRING,\n  LAST_NAME STRING,\n  E_MAIL STRING,\n  PHONE_NUMBER STRING,\n  CHILDREN_COUNT INT,\n  GENDER STRING,\n  MARITAL_STATUS STRING,\n  MENU_ITEM_ID INT,\n  MENU_ITEM_NAME STRING,\n  QUANTITY INT,\n  UNIT_PRICE FLOAT,\n  PRICE FLOAT,\n  ORDER_AMOUNT FLOAT,\n  ORDER_TAX_AMOUNT FLOAT,\n  ORDER_DISCOUNT_AMOUNT FLOAT,\n  ORDER_TOTAL FLOAT\n);\n\ncopy into HOL_DB.public.tasty_bytes_orders\nfrom @frostbytes/harmonized/orders_v.csv\non_error = continue;"
  },
  {
   "cell_type": "markdown",
   "id": "78585399-0c71-4363-9efe-c1bb3e0afa1b",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": "## Python UDFs\n\nSnowflake provides a variey of built-in functions like [`SUM()`](https://docs.snowflake.com/en/sql-reference/functions/sum), [`REGEXP_REPLACE()`](https://docs.snowflake.com/en/sql-reference/functions/regexp_replace), [`SEARCH()`](https://docs.snowflake.com/en/sql-reference/functions/search) and so on. But what if we need a function that isn't provided? That's where [User Defined Functions](https://docs.snowflake.com/en/developer-guide/udf/udf-overview) (UDF) come in! In Snowflake, we can write UDFs in **SQL**, **Python**, **Java**, **Scala**, and **JavaScript**. There are  3 types of UDFs: scalar, tabular, and aggregate. Let's go over the different UDF types: \n\n| Type      | Input            | Output              | Description                                                                                                                                                                            |\n|-----------|------------------|---------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Scalar    | 1 row          | 1 row             | This is probably the type of UDF you think of intuitively. For every input row, this returns an output row (one in, one out).                                                          |\n| Tabular   | 1 row          | 1+ rows    | UDTFs can return multiple rows for a single input row. Common examples include breaking up arrays or objects into multiple rows by their attributes.                                   |\n| Aggregate | 1+ rows | 1 row (per group) | UDAFs can help you do, well, aggregations! UDAFs are similar to functions like SUM, AVG, and STDDEV: you can use them with GROUP BY clauses to calculate domain-specific aggregations. |\n\nIf you've used UDFs before, you may be familiar with [Vectorized UDFs](https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs#label-snowpark-python-udf-vectorized), which allow you to process **batches** of rows at a time in your scalar and tabular UDFs. When you tag a scalar UDF or UDTF with the `@vectorized` decorator, that tells Snowflake to provide batches of input rows to your UDF/UDTF in the form of [pandas DataFrames](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html). This can be helpful for using Python libraries that operate on pandas DataFrames, and can be more performant for some workloads. Vectorized UDFs and UDTFs are only supported for Python."
  },
  {
   "cell_type": "markdown",
   "id": "7c907d40-4a06-4dcb-8ef9-8d0b3fe257b1",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": "### Writing UDFs\n\nTo create a UDF with Python, we can annotate a Python method with the [`@udf`](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.udf) decorator. This will use your Snowpark Session to create the UDF. (Under the hood it will run `CREATE OR REPLACE` with the source code to create the object.) Or, we can run [`Session.udf.register()`](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.udf.UDFRegistration.register#snowflake.snowpark.udf.UDFRegistration.register) and pass in a reference to the Python method. \n\nLet's create a basic UDF and call it in a query. The UDF will parse the customer's email address and return whether the domain name is from a commonly known free provider or not. This is helpful to target customers who may be interested in catering for events at their business."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df71ff-1dcd-4ae5-b01b-1c634d9cf328",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# Create a UDF\n",
    "from snowflake.snowpark.functions import udf\n",
    "\n",
    "def email_provider_type(email: str) -> str:\n",
    "    if not email:\n",
    "        return 'UNKNOWN'\n",
    "    domain = email.split('@')[-1].lower()\n",
    "    \n",
    "    if domain in ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com']:\n",
    "        return 'FREE'\n",
    "    else:\n",
    "        return 'CORPORATE'\n",
    "\n",
    "udf = session.udf.register(email_provider_type, name='email_provider_type')\n",
    "\n",
    "print(f'Created a temporary UDF named {udf.name}. Use it in a query!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301b7a6-572e-41c0-85e0-1a44c364ae56",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "-- Now we can call this UDF in a SQL query\n",
    "SELECT E_MAIL, email_provider_type(E_MAIL)\n",
    "FROM HOL_DB.PUBLIC.TASTY_BYTES_ORDERS\n",
    "WHERE E_MAIL != ''\n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e0217-dee0-429c-9541-c4f1e9e522f9",
   "metadata": {
    "collapsed": false,
    "name": "cell8"
   },
   "source": "## More UDFs\n\nWrite a UDF that takes as input a phone number from the `PHONE_NUMBER` column and returns the last 4 digits of that phone number. Then register the UDF using [`session.udf.register()`](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.31.0/snowpark/api/snowflake.snowpark.udf.UDFRegistration.register). Finally, call it in a SQL query."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eac1f6-8357-4f23-a796-6e6c0ee59f00",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "def get_last4_phone(phone_number: str) -> str:\n    if not phone_number:\n        return \"\"\n    return phone_number[-4:]\n\n# Register it\nudf = session.udf.register(get_last4_phone, name='get_last4_phone')\n\nprint(f'Your UDF named {udf.name} has been created.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb559b71-8cc9-47c8-84eb-1ced81575b79",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "SELECT E_MAIL, PHONE_NUMBER, get_last4_phone(PHONE_NUMBER) AS HIDDEN_PHONE_NO\nFROM HOL_DB.PUBLIC.TASTY_BYTES_ORDERS\nWHERE PHONE_NUMBER != ''\nLIMIT 1000;"
  },
  {
   "cell_type": "markdown",
   "id": "f5df68a4-f68a-4338-9083-cab10643eb10",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": "### Writing a UDAF\n\nWhat is a [User Defined **Aggregate** Function](https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udafs) (UDAF)? UDAFs allow us to implement custom aggregation logic or aggregations that Snowflake does not provide built-in. UDAFs are inherently more complicated than scalar UDFs -- we have multiple input rows per group which need to be aggregated. Therefore, we will use a [Python Class](https://www.w3schools.com/python/python_classes.asp) to implement the required methods. The definition below illustrates the four methods that Snowflake needs.\n\n\n```python\nclass MyUDAF:\n    def ___init___(self):\n        self._initial_value = None\n\n    def accumulate(self, input_value):\n        # This is where input rows will be passed. In this method, aggregate the input_value with the\n        # self._initial_value. (For example: summing, appending to a list, etc.)\n        self._initial_value += input_value\n    \n    @property\n    def aggregate_state(self):\n        # This exposes the self._initial_value with a known name so Snowflake can access it during execution\n        return self._initial_value\n    \n    def merge(self, other_aggregate_state):\n        # This merges two intermediate aggregates. On large datasets, Snowflake will call this to merge \n        # intermediate results. The input, other_aggregate_state, is the @property of another instance of this class\n        self._inital_value += other_aggregate_state\n    \n    def finish(self):\n        # Snowflake will call this method to retrieve the final result\n        return self._partial_sum\n```\n\nHere is a concrete example. This UDAF calculates an average.\n\n```python\n@dataclass\nclass AvgAggState:\n    # An average is the sum of values divided by the count, so this tracks the rolling sum and counts.\n    sum: int\n    count: int\n\nclass PythonAvg:\n    def __init__(self):\n        # This is the initial value (sum and count are both set to 0)\n        self._agg_state = AvgAggState(0, 0)\n\n    @property\n    def aggregate_state(self):\n        # This exposes the intermediate state under a known property name, agregate_state, so Snowflake can access it.\n        return self._agg_state\n\n    def accumulate(self, input_value):\n        # input_value will be an input row, so we add the value to the sum and increment the count\n        sum = self._agg_state.sum\n        count = self._agg_state.count\n        \n        self._agg_state.sum = sum + input_value\n        self._agg_state.count = count + 1\n\n    def merge(self, other_agg_state):\n        # other_agg_state will be an AvgAggState, so we combine the sums and counts\n        sum = self._agg_state.sum\n        count = self._agg_state.count\n        \n        other_sum = other_agg_state.sum\n        other_count = other_agg_state.count\n        \n        self._agg_state.sum = sum + other_sum\n        self._agg_state.count = count + other_count\n\n    def finish(self):\n        # Finally, return the sum divided by the count!\n        sum = self._agg_state.sum\n        count = self._agg_state.count\n        return sum / count\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593934a3-32dc-449a-8d1b-4b5d11507183",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "from snowflake.snowpark.types import FloatType, DateType\n",
    "from snowflake.snowpark.functions import udaf\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.functions import udaf\n",
    "\n",
    "class LoyaltyScoreUDAF:\n",
    "    def __init__(self):\n",
    "        self.total_orders: int = 0\n",
    "        self.total_value: float = 0\n",
    "        self.last_order_ts: datetime = None\n",
    "\n",
    "    def accumulate(self, order_total, order_ts):\n",
    "        if order_total is not None:\n",
    "            self.total_orders += 1\n",
    "            self.total_value += order_total\n",
    "            \n",
    "        if order_ts is not None:\n",
    "            if self.last_order_ts is None or order_ts > self.last_order_ts:\n",
    "                self.last_order_ts = order_ts\n",
    "\n",
    "    def merge(self, other: tuple):\n",
    "        self.total_orders += other[0]\n",
    "        self.total_value += other[1]\n",
    "        if self.last_order_ts is None or (other[2] and other[2] > self.last_order_ts):\n",
    "            self.last_order_ts = other[2]\n",
    "\n",
    "    def finish(self):\n",
    "        if self.total_orders == 0:\n",
    "            return 0.0\n",
    "        avg_order_value = self.total_value / self.total_orders\n",
    "        \n",
    "        now = datetime.utcnow().date()\n",
    "        days_since_last = (now - self.last_order_ts).days if self.last_order_ts else 999\n",
    "        recency_boost = 1 / (days_since_last + 1)\n",
    "\n",
    "        # Weighting parameters\n",
    "        w1, w2, w3 = 1.0, 0.1, 5.0\n",
    "\n",
    "        return (\n",
    "            w1 * math.log(self.total_orders + 1) +\n",
    "            w2 * avg_order_value +\n",
    "            w3 * recency_boost\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def aggregate_state(self):\n",
    "        return (self.total_orders, self.total_value, self.last_order_ts)\n",
    "      \n",
    "loyalty_udaf = udaf(\n",
    "    LoyaltyScoreUDAF, \n",
    "    name=\"LoyaltyScoreUDAF\",\n",
    "    is_permanent=True,\n",
    "    stage_location='@my_stage',\n",
    "    replace=True,\n",
    "    packages=['snowflake-telemetry-python'], # We'll learn about this in the next Notebook\n",
    "    return_type=FloatType(), \n",
    "    input_types=[FloatType(), DateType()])\n",
    "\n",
    "print(f'Created UDAF, \"{loyalty_udaf.name}\" ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dca55-3324-4bf1-ba82-f0ca47567292",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "  CUSTOMER_ID,\n",
    "  LoyaltyScoreUDAF(ORDER_TOTAL, ORDER_TS) AS loyalty_score\n",
    "FROM tasty_bytes_orders\n",
    "WHERE \n",
    "    ORDER_TOTAL IS NOT NULL \n",
    "    AND ORDER_TS IS NOT NULL\n",
    "    AND CUSTOMER_ID IS NOT NULL\n",
    "GROUP BY CUSTOMER_ID\n",
    "ORDER BY loyalty_score DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295c0ad-865f-496f-9e68-5bf60fd1554f",
   "metadata": {
    "collapsed": false,
    "name": "cell14"
   },
   "source": [
    "## Accessing External Data\n",
    "\n",
    "Next, let's leverage the flexbility of Python to enrich our Tasty Bytes orders data with weather data to understand how weather conditions impact customer behaviorâ€”do people order more tacos when it's sunny? Fewer smoothies when it's cold? \n",
    "\n",
    "To do so, we will use [OpenWeather](https://openweathermap.org/)'s [REST API](https://openweathermap.org/api/one-call-3#history) to fetch information about the weather for the time, longitude, and latitude when that order was made. OpenWeather allows you to make 1,000 API requests per day. Not familiar with REST APIs? Check out [this article](https://tutorialedge.net/software-eng/what-is-a-rest-api/), or feel free to call an instructor over for more information!\n",
    "\n",
    "First, let's create an External Access Integration to allow code in our Snowflake account to reach out to OpenWeatherMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e66846-ba39-44c1-b0ed-dcb069bb7fc3",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE NETWORK RULE openweathermap_network_rule\n",
    "  MODE = EGRESS\n",
    "  TYPE = HOST_PORT\n",
    "  VALUE_LIST = ('api.openweathermap.org');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e01b854-03e1-4074-a75c-9db86e151c7c",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE EXTERNAL ACCESS INTEGRATION openweathermap_access_integration\n",
    "  ALLOWED_NETWORK_RULES = (openweathermap_network_rule)\n",
    "  ENABLED = true;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed6b03c-ba0f-4f64-98ea-9065d1e6e50a",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "Now that the network rule and external access integration are created, we need to associate it with this Notebook by following [these steps](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-external-access#enable-external-access-integrations-eai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0fd26-c417-4861-b808-1999ee25719e",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "# Since the Notebook was restarted, let's re-import these modules re-create the session object.\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413b2fb-199f-4a56-b54f-bf1e95fdb94b",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "def get_url(lat, lon, time):\n    # This function constructs the URL that we will send requests to\n    API_KEY = '7089750f9c4d22fe2202c3b635e24b80'\n    \n    return f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&dt={time}&exclude=hourly,daily&appid={API_KEY}'\n    \n# Let's try it here:\nexample_url = get_url(37.7749, -122.4194, 1744596465)\n\nprint(f'Example URL to send requests to...\\n{example_url}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f2c03-aeca-4709-bba1-f6a716fccd6d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "import requests\nfrom datetime import datetime\n\ndef get_weather(lat: int, long: int, time: datetime):\n    # This will get the temp, cloudiness, and description for the weather at the given latitude, longitude, and time.\n\n    epoch_time = int(time.timestamp())\n    \n    url = get_url(lat, long, epoch_time)\n    response = requests.get(url)\n    \n    if response.ok:\n        json_ = response.json()\n        # Pull out the data we want\n        return {\n            'temp': json_['main']['temp'],\n            'cloudiness': json_['clouds']['all'],\n            'description': json_['weather'][0]['description']\n        }\n    else:# Bad response\n        print(f\"Error: {response.status_code}\")\n        return None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e13ab0-da13-43c0-83c9-0971a5844aee",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "print(\"Let's do a test run of the function!\")\nget_weather(10.8231, 106.6297, datetime(2002, 3, 19, 12, 30, 0))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04714273-c51c-4971-a040-10886d3bf03b",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import VariantType, StringType, LongType, TimestampTimeZone, TZ, TimestampType\n",
    "\n",
    "weather_udf = session.udf.register(\n",
    "    get_weather,\n",
    "    name='get_weather',\n",
    "    replace=True,\n",
    "    return_type=StringType(),\n",
    "    input_types=[StringType(), StringType(), TimestampType(TimestampTimeZone.TZ)],\n",
    "    packages=['requests', 'snowflake-telemetry-python'],\n",
    "    external_access_integrations=['openweathermap_access_integration']\n",
    ")\n",
    "\n",
    "print(f'Created weather UDF, {weather_udf.name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8bf168-d064-412e-90b3-f05a4d5a2eb6",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": "SELECT \n    latitude, longitude, order_ts, \n    get_weather(latitude, longitude, order_ts) as weather\nFROM TASTY_BYTES_ORDERS\nLIMIT 5;"
  },
  {
   "cell_type": "markdown",
   "id": "454bef4c-8e2e-4468-a106-883fb0484a7c",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": "## Update the UDF\n\nThe `get_weather()` method returns the temp, cloudiness, and description of the weather but there are other attributes in the `json_` object that we could include. Use the space below to explore the API response and try updating the `get_weather()` UDF to return more data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df9966-d1e7-4082-9f81-462b206742e6",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": "# Here's some setup code to get started!\nimport json \n\nlat = 37.7749\nlon = 122.4194\nepoch_time = int(datetime(2023, 1, 1, 12, 30, 0).timestamp())\n\nurl = get_url(lat, lon, epoch_time)\nprint(url)\nresponse = requests.get(url)\n\nresponse.json()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ad89c-224f-46d0-93e2-9e193278fc7e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": "import requests\nfrom datetime import datetime\n\ndef get_weather(lat: float, long: float, time: datetime):\n    epoch_time = int(time.timestamp())\n    url = get_url(lat, long, epoch_time)\n    response = requests.get(url)\n\n    if response.ok:\n        json_ = response.json()\n        \n        # Extract the data from the response\n        weather_data = {\n            # Main conditions\n            'temp': json_['main']['temp'],\n            'feels_like': json_['main'].get('feels_like'),\n            'temp_min': json_['main'].get('temp_min'),\n            'temp_max': json_['main'].get('temp_max'),\n            'pressure': json_['main'].get('pressure'),\n            'humidity': json_['main'].get('humidity'),\n\n            # Weather description\n            'description': json_['weather'][0].get('description'),\n            'main_condition': json_['weather'][0].get('main'),\n\n            # Clouds and visibility\n            'cloudiness': json_['clouds'].get('all'),\n            'visibility': json_.get('visibility'),\n\n            # Wind\n            'wind_speed': json_['wind'].get('speed'),\n            'wind_deg': json_['wind'].get('deg'),\n            'wind_gust': json_['wind'].get('gust'),\n\n            # Sys (system info: sunrise/sunset)\n            'sunrise': json_['sys'].get('sunrise'),\n            'sunset': json_['sys'].get('sunset'),\n\n            # Coordinates (for confirmation)\n            'lat': json_['coord'].get('lat'),\n            'lon': json_['coord'].get('lon'),\n\n            # Time of data calculation\n            'dt': json_.get('dt'),\n        }\n        return weather_data\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n"
  },
  {
   "cell_type": "code",
   "id": "85f4bdbc-307a-4c57-8a8b-846807ae0d73",
   "metadata": {
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.types import VariantType, StringType, LongType, TimestampTimeZone, TZ, TimestampType\n\nweather_udf = session.udf.register(\n    get_weather,\n    name='get_weather',\n    replace=True,\n    # return_type=StringType(),\n    return_type=VariantType(),\n    input_types=[StringType(), StringType(), TimestampType(TimestampTimeZone.TZ)],\n    packages=['requests', 'snowflake-telemetry-python'],\n    external_access_integrations=['openweathermap_access_integration']\n)\n\nprint(f'Updated weather UDF, {weather_udf.name}, successfully.')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff0c26c1-202d-495f-83e7-ceb56353feed",
   "metadata": {
    "language": "sql",
    "name": "cell28"
   },
   "outputs": [],
   "source": "-- Query to tes the updated get_weahter\nSELECT \n    latitude, \n    longitude, \n    order_ts, \n    get_weather(latitude, longitude, order_ts) AS weather, \n    weather:\"temp\"        AS temperature,\n    weather:\"feels_like\"::FLOAT  AS feels_like,\n    weather:\"humidity\"::INT      AS humidity,\n    weather:\"description\"::STRING AS description,\n    weather:\"wind_speed\"::FLOAT  AS wind_speed,\n    weather:\"cloudiness\"::INT    AS cloudiness\nFROM TASTY_BYTES_ORDERS\nLIMIT 100;",
   "execution_count": null
  }
 ]
}